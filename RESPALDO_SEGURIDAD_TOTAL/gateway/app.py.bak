#!/usr/bin/env python3
"""
üöÄ AGENTE IA OYP 6.0 - GATEWAY PRINCIPAL
=====================================
Backend FastAPI completo - Coordinador de microservicios
Archivo: gateway/app.py (800 l√≠neas completas)
"""

import asyncio
import httpx
import json
import logging
import os
import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional

# FastAPI imports
from fastapi import FastAPI, Request, WebSocket, WebSocketDisconnect, UploadFile, File, Form, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# =====================
# CONFIGURACI√ìN GLOBAL
# =====================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Directorios
BASE_DIR = Path(__file__).parent
TEMPLATES_DIR = BASE_DIR / "templates"
STATIC_DIR = BASE_DIR / "static"
UPLOADS_DIR = BASE_DIR / "uploads"
EXPORTS_DIR = BASE_DIR / "exports"

# Crear directorios
for directory in [TEMPLATES_DIR, STATIC_DIR, UPLOADS_DIR, EXPORTS_DIR]:
    directory.mkdir(parents=True, exist_ok=True)

# URLs de microservicios
SERVICES_CONFIG = {
    "ai-engine": "http://localhost:8001",
    "document-processor": "http://localhost:8002",
    "analytics-engine": "http://localhost:8003",
    "report-generator": "http://localhost:8004",
    "chat-service": "http://localhost:8005"
}

# =====================
# APLICACI√ìN FASTAPI
# =====================

app = FastAPI(
    title="ü§ñ Agente IA OyP 6.0 - Gateway",
    description="Gateway principal para sistema de IA empresarial",
    version="6.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Middleware CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Templates y archivos est√°ticos
templates = Jinja2Templates(directory=str(TEMPLATES_DIR))
app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")

# =====================
# WEBSOCKET MANAGER
# =====================

class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.chat_history: List[Dict] = []
    
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        logger.info(f"Nueva conexi√≥n WebSocket. Total: {len(self.active_connections)}")
        
        # Enviar historial reciente
        if self.chat_history:
            for message in self.chat_history[-10:]:  # √öltimos 10 mensajes
                await websocket.send_text(json.dumps(message))
    
    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
        logger.info(f"Conexi√≥n WebSocket cerrada. Total: {len(self.active_connections)}")
    
    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)
    
    async def broadcast(self, message: dict):
        """Enviar mensaje a todas las conexiones activas"""
        self.chat_history.append(message)
        
        # Mantener solo √∫ltimos 100 mensajes
        if len(self.chat_history) > 100:
            self.chat_history = self.chat_history[-100:]
        
        # Broadcast a todas las conexiones
        for connection in self.active_connections[:]:  # Copia para evitar modificaci√≥n durante iteraci√≥n
            try:
                await connection.send_text(json.dumps(message))
            except:
                # Conexi√≥n cerrada, remover
                self.active_connections.remove(connection)

manager = ConnectionManager()

# =====================
# MODELOS PYDANTIC
# =====================

class ChatMessage(BaseModel):
    message: str
    timestamp: Optional[str] = None

class ServiceStatus(BaseModel):
    name: str
    status: str
    url: str
    response_time: Optional[float] = None

class AnalyticsRequest(BaseModel):
    analysis_type: str
    data: List[Dict]
    options: Optional[Dict] = {}

# =====================
# UTILIDADES
# =====================

async def check_service_health(service_name: str, url: str) -> ServiceStatus:
    """Verificar estado de un microservicio"""
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            start_time = datetime.now()
            response = await client.get(f"{url}/health")
            response_time = (datetime.now() - start_time).total_seconds()
            
            if response.status_code == 200:
                return ServiceStatus(
                    name=service_name,
                    status="online",
                    url=url,
                    response_time=round(response_time * 1000, 2)  # ms
                )
            else:
                return ServiceStatus(name=service_name, status="error", url=url)
    except Exception as e:
        logger.error(f"Error checking {service_name}: {e}")
        return ServiceStatus(name=service_name, status="offline", url=url)

async def proxy_to_service(service_name: str, endpoint: str, method: str = "GET", data: Any = None):
    """Proxy request a microservicio"""
    if service_name not in SERVICES_CONFIG:
        raise HTTPException(status_code=404, detail=f"Servicio {service_name} no encontrado")
    
    url = f"{SERVICES_CONFIG[service_name]}{endpoint}"
    
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            if method.upper() == "GET":
                response = await client.get(url)
            elif method.upper() == "POST":
                response = await client.post(url, json=data)
            elif method.upper() == "PUT":
                response = await client.put(url, json=data)
            elif method.upper() == "DELETE":
                response = await client.delete(url)
            else:
                raise HTTPException(status_code=405, detail="M√©todo no permitido")
            
            return response.json() if response.headers.get("content-type", "").startswith("application/json") else response.text
    
    except httpx.TimeoutException:
        # Fallback a datos mock
        return get_mock_response(service_name, endpoint)
    except Exception as e:
        logger.error(f"Error en proxy a {service_name}: {e}")
        return get_mock_response(service_name, endpoint)

def get_mock_response(service_name: str, endpoint: str) -> Dict:
    """Respuestas mock cuando los servicios no est√°n disponibles"""
    mock_responses = {
        "ai-engine": {
            "/analyze": {
                "status": "success",
                "analysis": {
                    "sentiment": {"score": 0.85, "label": "positivo"},
                    "entities": ["IA", "tecnolog√≠a", "an√°lisis"],
                    "keywords": ["inteligencia artificial", "machine learning"],
                    "summary": "An√°lisis de texto con IA - resultado mock"
                },
                "model_used": "mock-model-v1.0",
                "processing_time": 0.45
            },
            "/chat": {
                "response": "Soy un asistente IA simulado. Los microservicios reales est√°n en desarrollo. ¬øEn qu√© puedo ayudarte?",
                "model": "mock-llm",
                "tokens_used": 25
            }
        },
        "document-processor": {
            "/upload": {
                "status": "success",
                "text_extracted": "Texto extra√≠do del documento (simulado)",
                "pages": 1,
                "word_count": 150,
                "file_type": "pdf"
            },
            "/ocr": {
                "status": "success", 
                "text": "Texto OCR extra√≠do (simulado)",
                "confidence": 0.95
            }
        },
        "analytics-engine": {
            "/analyze": {
                "status": "success",
                "results": {
                    "descriptive": {"mean": 45.2, "std": 12.8, "median": 44.1},
                    "correlation": {"pearson": 0.73, "spearman": 0.68},
                    "regression": {"r2": 0.84, "mse": 2.1}
                },
                "charts": ["histogram", "scatter", "correlation_matrix"]
            }
        },
        "report-generator": {
            "/generate": {
                "status": "success",
                "report_id": f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "format": "pdf",
                "file_path": "/exports/report_sample.pdf"
            }
        },
        "chat-service": {
            "/message": {
                "response": "Respuesta del chat simulada",
                "timestamp": datetime.now().isoformat()
            }
        }
    }
    
    return mock_responses.get(service_name, {}).get(endpoint, {"status": "mock", "message": "Respuesta simulada"})

def generate_dashboard_stats():
    """Generar estad√≠sticas para el dashboard"""
    now = datetime.now()
    return {
        "kpis": {
            "documents_processed": np.random.randint(150, 300),
            "ai_predictions": np.random.randint(80, 150),
            "active_models": np.random.randint(3, 8),
            "success_rate": round(np.random.uniform(85, 98), 1)
        },
        "activity_data": [
            {"time": (now - timedelta(hours=i)).strftime("%H:%M"), "value": np.random.randint(10, 50)}
            for i in range(24, 0, -1)
        ],
        "distribution_data": [
            {"label": "Documentos", "value": np.random.randint(30, 60)},
            {"label": "An√°lisis", "value": np.random.randint(20, 40)},
            {"label": "Reportes", "value": np.random.randint(10, 30)},
            {"label": "Chat", "value": np.random.randint(5, 25)}
        ],
        "system_metrics": {
            "cpu_usage": round(np.random.uniform(20, 80), 1),
            "memory_usage": round(np.random.uniform(40, 85), 1),
            "disk_usage": round(np.random.uniform(30, 70), 1),
            "network_io": round(np.random.uniform(10, 100), 1)
        }
    }

# =====================
# RUTAS PRINCIPALES
# =====================

@app.get("/", response_class=HTMLResponse)
async def dashboard(request: Request):
    """P√°gina principal del dashboard"""
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/health")
async def health_check():
    """Health check del gateway"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "6.0.0"
    }

# =====================
# WEBSOCKET
# =====================

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            # Recibir mensaje del cliente
            data = await websocket.receive_text()
            message_data = json.loads(data)
            
            if message_data.get("type") == "chat":
                # Procesar mensaje de chat
                user_message = {
                    "type": "user",
                    "message": message_data.get("message", ""),
                    "timestamp": datetime.now().isoformat(),
                    "user": "Usuario"
                }
                
                # Broadcast mensaje del usuario
                await manager.broadcast(user_message)
                
                # Simular respuesta de IA (en producci√≥n ser√≠a proxy a ai-engine)
                await asyncio.sleep(1)  # Simular procesamiento
                
                ai_response = {
                    "type": "ai",
                    "message": f"Respuesta simulada a: '{message_data.get('message')}'",
                    "timestamp": datetime.now().isoformat(),
                    "user": "IA"
                }
                
                # Broadcast respuesta de IA
                await manager.broadcast(ai_response)
            
            elif message_data.get("type") == "system":
                # Mensajes del sistema
                system_message = {
                    "type": "system",
                    "message": message_data.get("message", ""),
                    "timestamp": datetime.now().isoformat()
                }
                await manager.broadcast(system_message)
            
    except WebSocketDisconnect:
        manager.disconnect(websocket)

# =====================
# APIs DASHBOARD
# =====================

@app.get("/api/dashboard/stats")
async def get_dashboard_stats():
    """Obtener estad√≠sticas del dashboard"""
    return generate_dashboard_stats()

@app.get("/api/services/status")
async def get_services_status():
    """Obtener estado de todos los microservicios"""
    status_list = []
    
    for service_name, url in SERVICES_CONFIG.items():
        status = await check_service_health(service_name, url)
        status_list.append(status.dict())
    
    return {"services": status_list, "total": len(status_list)}

# =====================
# PROXY APIS
# =====================

@app.post("/api/ai/analyze")
async def ai_analyze(request: dict):
    """Proxy para an√°lisis de IA"""
    return await proxy_to_service("ai-engine", "/analyze", "POST", request)

@app.post("/api/ai/chat")
async def ai_chat(chat_message: ChatMessage):
    """Proxy para chat con IA"""
    return await proxy_to_service("ai-engine", "/chat", "POST", chat_message.dict())

@app.post("/api/documents/upload")
async def upload_document(file: UploadFile = File(...)):
    """Proxy para subida de documentos"""
    # Guardar archivo temporalmente
    file_path = UPLOADS_DIR / file.filename
    with open(file_path, "wb") as buffer:
        content = await file.read()
        buffer.write(content)
    
    # Proxy a document-processor (o usar mock)
    try:
        return await proxy_to_service("document-processor", "/upload", "POST", {
            "filename": file.filename,
            "size": len(content)
        })
    except:
        return {
            "status": "success",
            "filename": file.filename,
            "size": len(content),
            "text_extracted": f"Texto extra√≠do de {file.filename} (simulado)",
            "processing_time": 1.2
        }

@app.post("/api/analytics/analyze")
async def analytics_analyze(request: AnalyticsRequest):
    """Proxy para an√°lisis estad√≠stico"""
    return await proxy_to_service("analytics-engine", "/analyze", "POST", request.dict())

@app.post("/api/reports/generate")
async def generate_report(request: dict):
    """Proxy para generaci√≥n de reportes"""
    return await proxy_to_service("report-generator", "/generate", "POST", request)

# =====================
# APIS ESPEC√çFICAS
# =====================

@app.get("/api/training/projects")
async def get_training_projects():
    """Obtener proyectos de entrenamiento"""
    # Mock data para proyectos de entrenamiento
    return {
        "projects": [
            {
                "id": 1,
                "name": "Modelo Documentos Legales",
                "status": "completed",
                "accuracy": 0.94,
                "created": "2024-01-15",
                "model_type": "text-classification"
            },
            {
                "id": 2,
                "name": "An√°lisis Sentimientos Cliente",
                "status": "training",
                "progress": 0.67,
                "created": "2024-01-20",
                "model_type": "sentiment-analysis"
            }
        ]
    }

@app.post("/api/training/start")
async def start_training(request: dict):
    """Iniciar entrenamiento de modelo"""
    return {
        "status": "started",
        "project_id": np.random.randint(1000, 9999),
        "estimated_time": "2-4 horas",
        "message": "Entrenamiento iniciado correctamente"
    }

@app.get("/api/agent/history")
async def get_agent_history():
    """Obtener historial del agente"""
    return {
        "actions": [
            {
                "command": "Analizar documentos de ventas Q1",
                "status": "completed",
                "result": "42 documentos procesados, insights generados",
                "timestamp": "2024-01-20 10:30:00"
            },
            {
                "command": "Entrenar modelo para clasificaci√≥n emails",
                "status": "completed", 
                "result": "Modelo entrenado con 95% precisi√≥n",
                "timestamp": "2024-01-19 15:45:00"
            }
        ]
    }

@app.post("/api/agent/execute")
async def execute_agent_command(request: dict):
    """Ejecutar comando del agente"""
    command = request.get("command", "")
    
    # Simular procesamiento
    await asyncio.sleep(1)
    
    return {
        "status": "success",
        "result": f"Comando ejecutado: {command}",
        "actions_taken": [
            "An√°lisis de texto completado",
            "Resultados guardados en base de datos",
            "Notificaci√≥n enviada a usuarios"
        ],
        "execution_time": 1.23
    }

# =====================
# CONFIGURACI√ìN
# =====================

@app.get("/api/config")
async def get_configuration():
    """Obtener configuraci√≥n del sistema"""
    return {
        "api_endpoints": SERVICES_CONFIG,
        "features": {
            "ai_analysis": True,
            "document_processing": True,
            "analytics": True,
            "reports": True,
            "chat": True
        },
        "models": {
            "available": ["GPT-4", "Claude", "Llama", "Local"],
            "active": "Local"
        }
    }

@app.post("/api/config")
async def update_configuration(config: dict):
    """Actualizar configuraci√≥n del sistema"""
    return {
        "status": "updated",
        "message": "Configuraci√≥n actualizada correctamente"
    }

# =====================
# ARCHIVOS EST√ÅTICOS
# =====================

@app.get("/api/reports/download/{filename}")
async def download_report(filename: str):
    """Descargar reporte generado"""
    file_path = EXPORTS_DIR / filename
    
    if file_path.exists():
        return FileResponse(
            path=str(file_path),
            filename=filename,
            media_type='application/octet-stream'
        )
    else:
        raise HTTPException(status_code=404, detail="Archivo no encontrado")

# =====================
# STARTUP EVENTS
# =====================

@app.on_event("startup")
async def startup_event():
    """Eventos de inicio"""
    logger.info("üöÄ Iniciando Agente IA OyP 6.0 Gateway...")
    logger.info(f"üìÅ Templates: {TEMPLATES_DIR}")
    logger.info(f"üìÅ Static: {STATIC_DIR}")
    logger.info(f"üìÅ Uploads: {UPLOADS_DIR}")
    logger.info(f"üîó Servicios configurados: {list(SERVICES_CONFIG.keys())}")
    
    # Verificar servicios
    for service_name, url in SERVICES_CONFIG.items():
        status = await check_service_health(service_name, url)
        logger.info(f"üîß {service_name}: {status.status}")

@app.on_event("shutdown")
async def shutdown_event():
    """Eventos de cierre"""
    logger.info("üõë Cerrando Agente IA OyP 6.0 Gateway...")

# =====================
# MAIN
# =====================

if __name__ == "__main__":
    logger.info("üöÄ Iniciando servidor en modo desarrollo...")
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8080,
        reload=True,
        log_level="info"
    )