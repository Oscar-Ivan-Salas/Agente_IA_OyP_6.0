#!/usr/bin/env python3
"""
üöÄ SETUP AI ENGINE v6.0 - VERSI√ìN CORREGIDA
Para ejecutar desde services/ai-engine/
"""

import os
import sys
import subprocess
from pathlib import Path

def create_ai_engine_structure():
    """Crear estructura del AI Engine"""
    print("üìÅ Creando estructura del AI Engine...")
    
    # Crear directorios
    directories = [
        "models", "routers", "services", "utils", "tests", 
        "logs", "data", "config", "cache"
    ]
    
    for directory in directories:
        Path(directory).mkdir(exist_ok=True)
        # Crear __init__.py
        (Path(directory) / "__init__.py").touch()
    
    print("‚úÖ Estructura de directorios creada")

def create_optimized_app():
    """Crear app.py optimizada"""
    print("üîß Creando app.py optimizada...")
    
    app_content = '''"""
AI Engine v6.0 - Motor de IA H√≠brido
Integrado con Agente IA OyP 6.0
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import os
import logging
from contextlib import asynccontextmanager
from typing import Dict, Any

# Imports locales (con manejo de errores)
try:
    from models.llm_hybrid_engine import HybridLLMEngine
    from services.model_manager import ModelManager
    from utils.config import Settings
    from utils.logging_config import setup_logging
    from routers import generation, analysis, chat, models
    IMPORTS_OK = True
except ImportError as e:
    print(f"‚ö†Ô∏è Error importando m√≥dulos: {e}")
    IMPORTS_OK = False

# Configuraci√≥n global
if IMPORTS_OK:
    settings = Settings()
    model_manager = ModelManager()
    hybrid_engine = None
else:
    settings = None
    model_manager = None
    hybrid_engine = None

# Configurar logging b√°sico
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Ciclo de vida de la aplicaci√≥n"""
    global hybrid_engine
    
    logger.info("üöÄ Iniciando AI Engine v6.0...")
    
    if not IMPORTS_OK:
        logger.warning("‚ö†Ô∏è M√≥dulos no disponibles, modo b√°sico")
        yield
        return
    
    try:
        # Inicializar motor h√≠brido
        hybrid_engine = HybridLLMEngine()
        await hybrid_engine.initialize()
        
        # Configurar model manager
        model_manager.set_engine(hybrid_engine)
        
        logger.info("‚úÖ AI Engine inicializado correctamente")
        
    except Exception as e:
        logger.error(f"‚ùå Error inicializando AI Engine: {e}")
        # No lanzar excepci√≥n, permitir que funcione en modo b√°sico
    
    yield
    
    # Cleanup
    logger.info("üîÑ Cerrando AI Engine...")
    if hybrid_engine:
        try:
            await hybrid_engine.cleanup()
        except:
            pass

# Crear aplicaci√≥n FastAPI
app = FastAPI(
    title="AI Engine v6.0",
    description="Motor de IA H√≠brido para Agente IA OyP",
    version="6.0.0",
    lifespan=lifespan
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Endpoints b√°sicos
@app.get("/")
async def root():
    """Endpoint ra√≠z"""
    return {
        "message": "AI Engine v6.0 - Agente IA OyP",
        "version": "6.0.0",
        "status": "active",
        "features": ["local_models", "cloud_apis", "hybrid_inference"],
        "imports_ok": IMPORTS_OK
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    try:
        # Verificar estado del motor
        if hybrid_engine and IMPORTS_OK:
            engine_status = await hybrid_engine.health_check()
        else:
            engine_status = {"status": "basic_mode"}
        
        return {
            "status": "healthy",
            "service": "ai-engine",
            "version": "6.0.0",
            "engine": engine_status,
            "imports_ok": IMPORTS_OK
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {
            "status": "healthy",
            "service": "ai-engine",
            "version": "6.0.0",
            "mode": "basic",
            "note": "Running in basic mode"
        }

@app.get("/info")
async def service_info():
    """Informaci√≥n detallada del servicio"""
    info = {
        "name": "AI Engine",
        "version": "6.0.0", 
        "description": "Motor de IA H√≠brido",
        "capabilities": [
            "text_generation",
            "text_analysis", 
            "chat_completion",
            "model_management"
        ],
        "endpoints": {
            "generation": "/generate/*",
            "analysis": "/analyze/*", 
            "chat": "/chat/*",
            "models": "/models/*"
        },
        "imports_ok": IMPORTS_OK
    }
    
    # Agregar informaci√≥n de modelos si est√° disponible
    if hybrid_engine and IMPORTS_OK:
        try:
            available_models = await hybrid_engine.get_available_models()
            info["available_models"] = available_models
        except Exception as e:
            logger.warning(f"Could not get model info: {e}")
    
    return info

@app.get("/stats")
async def get_stats():
    """Estad√≠sticas del servicio"""
    if not hybrid_engine or not IMPORTS_OK:
        return {
            "mode": "basic",
            "requests": 0,
            "note": "Stats not available in basic mode"
        }
    
    try:
        stats = await hybrid_engine.get_stats()
        return stats
    except Exception as e:
        logger.error(f"Error getting stats: {e}")
        return {"error": "Could not retrieve stats"}

# Incluir routers si est√°n disponibles
if IMPORTS_OK:
    try:
        app.include_router(generation.router, prefix="/generate", tags=["Generation"])
        app.include_router(analysis.router, prefix="/analyze", tags=["Analysis"])
        app.include_router(chat.router, prefix="/chat", tags=["Chat"])
        app.include_router(models.router, prefix="/models", tags=["Models"])
    except Exception as e:
        logger.warning(f"Error including routers: {e}")

# Handler de errores global
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"Unhandled exception: {exc}")
    return JSONResponse(
        status_code=500,
        content={"error": "Internal server error", "detail": str(exc)}
    )

if __name__ == "__main__":
    port = 8001
    debug_mode = os.getenv("DEBUG", "false").lower() == "true"
    
    print(f"üöÄ Iniciando AI Engine en puerto {port}")
    print(f"üìö Documentaci√≥n: http://localhost:{port}/docs")
    
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=port,
        reload=debug_mode,
        log_level="info"
    )
'''
    
    with open("app.py", "w", encoding="utf-8") as f:
        f.write(app_content)
    
    print("‚úÖ app.py optimizada creada")

def create_basic_components():
    """Crear componentes b√°sicos para que funcione"""
    print("üîß Creando componentes b√°sicos...")
    
    # Config b√°sica
    config_content = '''"""
Configuraci√≥n b√°sica
"""

import os
from typing import Optional

class Settings:
    def __init__(self):
        self.app_name = "AI Engine v6.0"
        self.debug = os.getenv("DEBUG", "false").lower() == "true"
        
        # APIs opcionales
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.anthropic_api_key = os.getenv("ANTHROPIC_API_KEY")
        self.google_api_key = os.getenv("GOOGLE_API_KEY")
        
        # Configuraci√≥n
        self.enable_local_models = True
        self.enable_cloud_models = True
        self.models_cache_dir = "./cache"
'''
    
    with open("utils/config.py", "w", encoding="utf-8") as f:
        f.write(config_content)
    
    # Logging b√°sico
    logging_content = '''"""
Configuraci√≥n de logging b√°sica
"""

import logging

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
'''
    
    with open("utils/logging_config.py", "w", encoding="utf-8") as f:
        f.write(logging_content)
    
    # Model Manager b√°sico
    model_manager_content = '''"""
Gestor de modelos b√°sico
"""

class ModelManager:
    def __init__(self):
        self.engine = None
    
    def set_engine(self, engine):
        self.engine = engine
    
    async def reload_models(self):
        return True
'''
    
    with open("services/model_manager.py", "w", encoding="utf-8") as f:
        f.write(model_manager_content)
    
    # Router b√°sico de generaci√≥n
    generation_router = '''"""
Router b√°sico de generaci√≥n
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Optional
import logging

logger = logging.getLogger(__name__)
router = APIRouter()

class GenerationRequest(BaseModel):
    prompt: str
    max_length: Optional[int] = 150
    temperature: Optional[float] = 0.7

@router.post("/text")
async def generate_text(request: GenerationRequest):
    """Generar texto - versi√≥n b√°sica"""
    try:
        # Respuesta simulada para que funcione
        return {
            "response": f"Respuesta simulada para: {request.prompt[:50]}...",
            "engine": "basic",
            "model": "demo",
            "tokens": len(request.prompt.split()),
            "timestamp": "2024-01-01T00:00:00"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/models")
async def get_models():
    return {"models": ["basic", "demo"]}
'''
    
    with open("routers/generation.py", "w", encoding="utf-8") as f:
        f.write(generation_router)
    
    # Routers b√°sicos
    for router_name in ["analysis", "chat", "models"]:
        router_content = f'''"""
Router b√°sico {router_name}
"""

from fastapi import APIRouter

router = APIRouter()

@router.get("/")
async def {router_name}_root():
    return {{"message": "{router_name} endpoint", "status": "basic"}}
'''
        
        with open(f"routers/{router_name}.py", "w", encoding="utf-8") as f:
            f.write(router_content)
    
    # Engine b√°sico
    engine_content = '''"""
Motor h√≠brido b√°sico - funciona sin dependencias pesadas
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict, List, Any

logger = logging.getLogger(__name__)

class HybridLLMEngine:
    def __init__(self):
        self.stats = {
            "requests_total": 0,
            "requests_local": 0, 
            "requests_cloud": 0,
            "errors": 0,
            "uptime_start": datetime.now()
        }
    
    async def initialize(self):
        logger.info("üîÑ Inicializando motor b√°sico...")
        # Simulaci√≥n de inicializaci√≥n
        await asyncio.sleep(0.1)
        logger.info("‚úÖ Motor b√°sico inicializado")
    
    async def generate_text(self, prompt: str, **kwargs) -> Dict[str, Any]:
        self.stats["requests_total"] += 1
        self.stats["requests_local"] += 1
        
        # Respuesta simulada b√°sica
        return {
            "response": f"Respuesta b√°sica para: {prompt[:50]}...",
            "engine": "basic",
            "model": "demo",
            "tokens": len(prompt.split()) + 10,
            "timestamp": datetime.now().isoformat()
        }
    
    async def get_available_models(self) -> List[str]:
        return ["basic:demo", "local:basic"]
    
    async def health_check(self) -> Dict[str, Any]:
        return {
            "status": "healthy",
            "mode": "basic",
            "requests": self.stats["requests_total"]
        }
    
    async def get_stats(self) -> Dict[str, Any]:
        return {
            **self.stats,
            "uptime": str(datetime.now() - self.stats["uptime_start"]),
            "mode": "basic"
        }
    
    async def cleanup(self):
        logger.info("üîÑ Limpiando motor b√°sico...")
'''
    
    with open("models/llm_hybrid_engine.py", "w", encoding="utf-8") as f:
        f.write(engine_content)
    
    print("‚úÖ Componentes b√°sicos creados")

def create_requirements():
    """Crear requirements b√°sicos"""
    print("üì¶ Creando requirements.txt...")
    
    requirements_content = '''# AI Engine v6.0 - Dependencias B√°sicas

# FastAPI y servidor (ESENCIALES)
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0

# Utilidades b√°sicas
python-dotenv==1.0.0
python-multipart==0.0.6
httpx==0.25.0

# Las siguientes son OPCIONALES - instalar solo si necesitas IA avanzada:

# # IA y ML (OPCIONAL - comentadas por defecto)
# torch>=2.0.0
# transformers>=4.35.0
# openai>=1.3.0
# anthropic>=0.7.0
# google-generativeai>=0.3.0

# # Procesamiento de texto (OPCIONAL)
# spacy>=3.7.0
# nltk>=3.8.0

# Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
'''
    
    with open("requirements.txt", "w", encoding="utf-8") as f:
        f.write(requirements_content)
    
    print("‚úÖ requirements.txt b√°sico creado")

def create_env_example():
    """Crear .env.example"""
    print("‚öôÔ∏è Creando .env.example...")
    
    env_content = '''# AI Engine v6.0 - Variables de Entorno

# Configuraci√≥n b√°sica
DEBUG=false

# APIs de IA (TODAS OPCIONALES - funciona sin ellas)
# OPENAI_API_KEY=tu_key_aqui
# ANTHROPIC_API_KEY=tu_key_aqui  
# GOOGLE_API_KEY=tu_key_aqui

# Configuraci√≥n avanzada
ENABLE_LOCAL_MODELS=true
ENABLE_CLOUD_MODELS=true
'''
    
    with open(".env.example", "w", encoding="utf-8") as f:
        f.write(env_content)
    
    print("‚úÖ .env.example creado")

def create_test_script():
    """Crear script de pruebas b√°sico"""
    print("üß™ Creando test_setup.py...")
    
    test_content = '''#!/usr/bin/env python3
"""
Pruebas b√°sicas del AI Engine v6.0
"""

import asyncio
import sys
from pathlib import Path

async def test_basic():
    print("üß™ Probando AI Engine v6.0...")
    
    try:
        # Test imports
        print("1Ô∏è‚É£ Probando imports...")
        from models.llm_hybrid_engine import HybridLLMEngine
        from utils.config import Settings
        print("‚úÖ Imports OK")
        
        # Test engine
        print("2Ô∏è‚É£ Probando motor...")
        engine = HybridLLMEngine()
        await engine.initialize()
        print("‚úÖ Motor OK")
        
        # Test generation
        print("3Ô∏è‚É£ Probando generaci√≥n...")
        result = await engine.generate_text("Hola mundo")
        print(f"‚úÖ Generaci√≥n OK: {result['response'][:30]}...")
        
        # Test health
        print("4Ô∏è‚É£ Probando health check...")
        health = await engine.health_check()
        print(f"‚úÖ Health OK: {health['status']}")
        
        await engine.cleanup()
        
        print("\\nüéâ Todas las pruebas pasaron!")
        print("\\nüìã Siguiente paso:")
        print("   uvicorn app:app --host 0.0.0.0 --port 8001")
        print("\\nüåê URLs:")
        print("   ‚Ä¢ API: http://localhost:8001")
        print("   ‚Ä¢ Docs: http://localhost:8001/docs")
        
        return True
        
    except Exception as e:
        print(f"\\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(test_basic())
    sys.exit(0 if success else 1)
'''
    
    with open("test_setup.py", "w", encoding="utf-8") as f:
        f.write(test_content)
    
    print("‚úÖ test_setup.py creado")

def main():
    """Funci√≥n principal"""
    print("üöÄ AI ENGINE v6.0 - SETUP CORREGIDO")
    print("=" * 50)
    
    try:
        # Verificar directorio
        if not Path("services/ai-engine").exists():
            print("‚ùå Error: Ejecutar desde directorio ra√≠z del proyecto")
            print("   Debe existir: services/ai-engine/")
            return False
        
        # Cambiar al directorio del AI Engine  
        os.chdir("services/ai-engine")
        print(f"üìÅ Trabajando en: {Path.cwd()}")
        
        # Crear todo
        create_ai_engine_structure()
        create_optimized_app()
        create_basic_components()
        create_requirements()
        create_env_example() 
        create_test_script()
        
        print("\n" + "=" * 50)
        print("‚úÖ AI ENGINE v6.0 CREADO EXITOSAMENTE")
        print("=" * 50)
        
        print("\nüöÄ Pr√≥ximos pasos:")
        print("   1. pip install -r requirements.txt")
        print("   2. python test_setup.py")
        print("   3. uvicorn app:app --host 0.0.0.0 --port 8001")
        
        print("\nüåê URLs:")
        print("   ‚Ä¢ API: http://localhost:8001")
        print("   ‚Ä¢ Docs: http://localhost:8001/docs")
        print("   ‚Ä¢ Health: http://localhost:8001/health")
        
        print("\nüí° Caracter√≠sticas:")
        print("   ‚úÖ Funciona inmediatamente (modo b√°sico)")
        print("   ‚úÖ APIs opcionales (instalar si necesitas)")
        print("   ‚úÖ Compatible con el gateway")
        print("   ‚úÖ Documentaci√≥n autom√°tica")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)